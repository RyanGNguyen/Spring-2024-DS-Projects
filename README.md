This repository contains various data science projects I have completed in Python over the course of the Spring 2024 (my Junior Spring) semester at Johns Hopkins University. My projects derive from two of my courses: Computational Stem Cell Biology (CSCB) and Information Retrieval and Web Agents (IRWA). 

The former focuses on studying the biology and differentiation capabilities of stem cells using RNA sequencing. The first two homeworks cover basic handling of RNA sequencing (RNA-Seq) data and supervised & unsupervised ML techniques for cell classification. The next homework covers cell differentiation trajectory inference to identify putative regulators of development. Then, the fourth homework explores stemness inference to inform trajectory inference and to help identify factors that can aid in maturation. Afterwards, the fifth homework applies this information towards gene regulatory network (GRN) inference & the creation of simulations to test the impact of perturbations on stem cell differentiation. Lastly, the final project culminates in the usage of all these techniques to create a cell line differentiation protocol for the development of embryonic mouse cells (epiblasts) into fully developed mouse ventricular cardiomyocytes, keeping note of relevant transcription factors and marker genes at each step. For more information, the official report is attached alongside the relevant scripts. All of these scripts rely on specialized Python bioinformatics libraries developed by JHU Assistant Professor of Biomedical Engineering and of Molecular Biology & Genetics Patrick Cahan. 

The latter focuses on information retrieval, natural language processing (NLP), and web agents (e.g. web crawlers, chatbots, etc.). The first homework explores the efficacy of various machine learning classifiers in basic text analysis problems. These include differentiating the use of periods to end sentences or for other contexts like acronyms and text segment classification as headers, plain text, etc. The second homework covers the use of basic vector models for information retrieval. This includes measuring the performance of different term weighting strategies (i.e. raw term frequencies, TF-IDF, boolean, etc.), similarity measures (i.e. cosine, Jacard, overlap, dice), evaluation metrics (e.g. mean precision, normalized recall, etc.), and preprocessing techniques (i.e. stemming, stopwords, etc.). The third homework extends the basic vector model in the previous homework for various text classification problems (i.e. word sense disambiguation, named entity classification, and spam detection). These extensions include using various word position weighting strategies, special adjacent tokens, and the use of SVD for computational efficiency. Next, the fourth homework involves the construction of a basic web crawler to scour explore the JHU CS department website starting from our instructor's course homepage. Lastly, the final extends this basic web crawler into a more advanced shopping bot that takes in personal information in the form of CSV files and permits the user to shop for books from either Amazon or Barnes & Nobles. 
